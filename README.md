# Simple version of SAGE (T-Bank)
- https://www.tbank.ru/career/technologies/sage/
- https://www.tbank.ru/software/sage/

## Описание
Лог-файлы являются важной частью работы любого сервера, так как они содержат информацию о том, какие запросы были отправлены на сервер, какие ошибки возникли и какие действия были выполнены.
Однако, обрабатывать и анализировать эти логи вручную может быть очень трудоемким процессом. Для решения этой проблемы напишем программу-анализатор логов.
На вход программе через аргументы командной строки задаётся:
- путь к одному или нескольким NGINX лог-файлам в виде локального шаблона или URL
- необязательные временные параметры from и to в формате ISO8601
- необязательный параметр формата вывода результата: markdown или adoc

Примеры вызова программы:
```
analyzer --path logs/2024* --from 2024-08-31 --format markdown

analyzer --path https://raw.githubusercontent.com/elastic/examples/master/Common%20Data%20Formats/nginx_logs/nginx_logs --format adoc

analyzer --path logs/**/2024-08-31.txt
```

Программа должна выполнять следующие задачи:
- Подсчитывать общее количество запросов
- Определять наиболее часто запрашиваемые ресурсы
- Определять наиболее часто встречающиеся коды ответа
- Рассчитывать средний размер ответа сервера

## Функциональные требования
Программа должна принимать на вход путь к лог-файлам, который может быть шаблоном для локальных файлов или URL.
Программа должна поддерживать опциональные параметры:
from и to для анализа записей в заданном временном диапазоне
выходной формат данных в виде markdown или adoc документа
Функции программы:
Подсчитывает общее количество запросов
Определяет наиболее часто запрашиваемые ресурсы
Определяет наиболее часто встречающиеся коды ответа
Рассчитывает средний размер ответа сервера
Рассчитывает 95% перцентиль размера ответа сервера

## Нефункциональные требования
Программа должна обрабатывать лог-файлы эффективно, не загружая весь файл в память.
Код должен быть написан ясно и структурировано в соответствии с требованиями, указанными в разделе "Требования к ДЗ" информационного блока.
Программа должна иметь четкую и понятную логику обработки ошибок.
Результат работы программы должен быть легко интерпретируемым человеком.

## Описание входных и выходных данных
## Входные данные
- Путь к лог-файлам: локальный путь (с поддержкой glob) или URL
- Временные параметры: `from` и `to` в формате ISO8601 (опционально).
- Формат вывода: `markdown` или `adoc` (опционально).
## Выходные данные
- Текстовый отчёт в выбранном формате с анализом логов.

## Пример вывода
#### Общая информация

|        Метрика        |     Значение |
| :-------------------: | -----------: |
|       Файл(-ы)        | `access.log` |
|    Начальная дата     |   31.08.2024 |
|     Конечная дата     |            - |
|  Количество запросов  |       10_000 |
| Средний размер ответа |         500b |
|  95p размера ответа   |         950b |

#### Запрашиваемые ресурсы

|     Ресурс      | Количество |
| :-------------: | ---------: |
|  `/index.html`  |      5_000 |
|  `/about.html`  |      2_000 |
| `/contact.html` |      1_000 |

#### Коды ответа

|  Код  |          Имя          | Количество |
| :---: | :-------------------: | ---------: |
|  200  |          OK           |       8000 |
|  404  |       Not Found       |       1000 |
|  500  | Internal Server Error |        500 |

## Инструкции по реализации
Разработайте парсер логов, который преобразует каждую строку лога в объект с полями, соответствующими структуре NGINX лог-файлов.
Реализуйте фильтрацию логов по временному диапазону, если таковые параметры предоставлены.
Соберите статистику по ключевым показателям: общее количество запросов, наиболее запрашиваемые ресурсы, коды ответов, средний размер ответа.
Форматирование результатов в markdown или adoc согласно предложенному шаблону.
Реализуйте функцию чтения лог-файлов, способную обработать как локальные файлы, так и загрузить данные с URL.
В конечном счете у вас должен получиться конвейер:
```
user input (file names, URL, etc) => Stream<LogRecord> => LogReport => текстовый отчёт в формате .md/.adoc
```
Схема NGINX-логов
```
'$remote_addr - $remote_user [$time_local] ' '"$request" $status $body_bytes_sent ' '"$http_referer" "$http_user_agent"'
```
Примеры логов можно взять по ссылке или создать самостоятельно:
```
docker run --rm -it -e 'RATE=10000' kscarlett/nginx-log-generator >> $HOME/logs.txt
```
После запуска подождите какое-то время (5-10с) и отправьте завершающий сигнал (Ctrl+C). Ваши логи будут в файле $HOME/logs.txt
Описание кодов HTTP протокола
https://developer.mozilla.org/en-US/docs/Web/HTTP/Status

## Тестирование
Проверка чтения файлов по локальному пути и через URL.
Тестирование парсера логов на корректность разбора формата логов.
Проверка фильтрации по временному диапазону на различных случаях.
Тесты для подсчета статистики, проверяющие правильность расчетов.
Валидация формата и содержимого выходного отчета.

## Ограничения и советы
- Совет: обратите внимание на формат логов NGINX и убедитесь, что ваш парсер может обрабатывать стандартный формат
- Ограничение: используйте потоковую обработку данных для работы с лог-файлами для уменьшения потребления памяти
- Ограничение: вся статистика должна собираться за один проход по данным
- Ограничение: логи нужно трансформировать в типизированное промежуточное представление
- Ограничение: для работы с датами можно использовать современные классы для работы со временем и путями
- Ограничение: для сбора статистики используйте коллекции, например, список или словарь


## Критерии оценки
За задание можно получить 100 баллов.
- +5 бонусных баллов, если реализуете 1 дополнительную статистику (максимум +10 баллов)
- +15 бонусных баллов, если реализуете поддержку фильтрации логов по значению, например:
```
analyzer --path logs/2024* --filter-field agent --filter-value "Mozilla*"
```
или
```
analyzer --path logs/2024* --filter-field method --filter-value "GET"
```
